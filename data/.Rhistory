library(rstan)
library(loo)
rm(list=ls())
# PS log likelihood / waic
load('../large_data/stanoutput_ps_Thu Jul_12_16-03-12_2018.rdata')
log.lik.ps = extract_log_lik(fit.ps, parameter_name = "logLik", merge_chains = TRUE)
waic.ps = waic(log.lik.ps)$estimates['waic','Estimate']
#waic.loo.ps = loo(log.lik.ps)
rm(fit.ps)
# PS (only reversions) log likelihood / waic
waic.ps.reversions = waic(log.lik.ps[,trials.reversions])$estimates['waic','Estimate']
load('../data/mostRecentPredDat_PS.rdata')
load('../data/mostRecentPredDat_DE.rdata')
pred.dat = pred.dat.ps %>%
left_join(pred.dat.de)
load('../data/mostRecentPredDat_PS_noRevert.rdata')
load('../data/mostRecentPredDat_DE_noRevert.rdata')
pred.dat.noRevert = pred.dat.ps.noRevert %>%
left_join(pred.dat.de.noRevert)
load('../data/mostRecentPredDat_PS_onlyRevert.rdata')
load('../data/mostRecentPredDat_DE_onlyRevert.rdata')
pred.dat.onlyRevert = pred.dat.ps.onlyRevert %>%
left_join(pred.dat.de.onlyRevert)
rm(pred.dat.ps, pred.dat.de, pred.dat.ps.noRevert, pred.dat.de.noRevert,
pred.dat.ps.onlyRevert, pred.dat.de.onlyRevert)
# use these later on to pull only relevant logLik out of fitted model
trials.reversions = which(pred.dat$reversions==TRUE)
trials.noReversions = which(pred.dat$reversions==FALSE)
waic.ps = waic(log.lik.ps)$estimates['waic','Estimate']
waic.ps.reversions = waic(log.lik.ps[,trials.reversions])$estimates['waic','Estimate']
#waic.loo.ps.reversions = loo(log.lik.ps.reversions)
# PS (no reversions) log likelihood / waic
waic.ps.noReversions = waic(log.lik.ps[,trials.noReversions])$estimates['waic','Estimate']
# PS log likelihood / waic
load('../large_data/stanoutput_ps_Thu Jul_12_16-03-12_2018.rdata')
log.lik.ps = extract_log_lik(fit.ps, parameter_name = "logLik", merge_chains = TRUE)
waic.ps = waic(log.lik.ps)$estimates['waic','Estimate']
#waic.loo.ps = loo(log.lik.ps)
rm(fit.ps)
# PS (only reversions) log likelihood / waic
waic.ps.reversions = waic(log.lik.ps[,trials.reversions])$estimates['waic','Estimate']
#waic.loo.ps.reversions = loo(log.lik.ps.reversions)
# PS (no reversions) log likelihood / waic
waic.ps.noReversions = waic(log.lik.ps[,trials.noReversions])$estimates['waic','Estimate']
#waic.loo.ps.noReversions = loo(log.lik.ps.noReversions)
# DE log likelihood / waic
load('../large_data/stanoutput_de_Tue_Jul_10_19-54-11_2018.rdata')
log.lik.de = extract_log_lik(fit.de, parameter_name = "logLik", merge_chains = TRUE)
waic.de = waic(log.lik.de)$estimates['waic','Estimate']
#waic.loo.de = loo(log.lik.de)
rm(fit.de)
# DE (only reversions) log likelihood / waic
waic.de.reversions = waic(log.lik.de[,trials.reversions])$estimates['waic','Estimate']
#waic.loo.de.reversions = loo(log.lik.de.reversions)
# DE (no reversions) log likelihood / waic
waic.de.noReversions = waic(log.lik.de[,trials.noReversions])$estimates['waic','Estimate']
#waic.loo.de.noReversions = loo(log.lik.de.noReversions)
waics = data_frame(
model = rep(c('Process Shift','Delayed Exponential'),times = 3),
data = c('full','full',
'noReversions','noReversions',
'onlyReversions','onlyReversions'),
waic = c(waic.ps,
waic.de$estimates,
waic.ps.noReversions,
waic.de.noReversions,
waic.ps.reversions,
waic.de.reversions)#,
# waic_loo = c(waic.loo.ps$estimates['looic','Estimate'],
#              waic.loo.de$estimates['looic','Estimate'],
#              waic.loo.ps.noReversions$estimates['looic','Estimate'],
#              waic.loo.de.noReversions$estimates['looic','Estimate'],
#              waic.loo.ps.reversions$estimates['looic','Estimate'],
#              waic.loo.de.reversions$estimates['looic','Estimate'])
)
ggplot(waics, aes(x = model, y = waic, fill = model))+
geom_bar(stat='identity', position = position_dodge())+
facet_grid(~data)+
theme_linedraw()+
scale_x_discrete(name = '', breaks=c(),labels=c())+
scale_y_continuous(expand=c(0,0))
p1.full <- lmer(score ~ group * age_group * gender + (1|sub_id), data=affiliation_data)
rm(list=ls())
library(ggplot2)
library(lme4)
library(lmerTest)
library(tidyverse)
library(forcats)
library(bootstrap)
library(plyr)
library(dplyr)
#DON'T USE plyr and ddplyr together (it messes up the summarize function)
## Theta and ci functions from Canada MC NEW.R
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),
1000,theta,x,na.rm=na.rm)$thetastar,
.025,na.rm=na.rm)
}
ci.high <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),
1000,theta,x,na.rm=na.rm)$thetastar,
.975,na.rm=na.rm) - mean(x,na.rm=na.rm)
}
setwd("~/Downloads/")
socialgroups<-read.csv('Social Groups Data RC.csv')
socialgroups <- subset(socialgroups, score != "NA")
socialgroups <- tbl_df(socialgroups)
socialgroups$age <- as.factor(socialgroups$age)
socialgroups$score <- as.numeric(socialgroups$score)
socialgroups$version <- as.factor(socialgroups$version)
# create data subsets
young <- socialgroups %>% filter(age %in% c('7','8'))
old <- socialgroups %>% filter(age %in% c('11','12'))
ladder_data <- socialgroups %>% filter(type %in% c("ladder1", "ladder2"))
affiliation_data <- setdiff(socialgroups,ladder_data)
affiliation_data <- affiliation_data %>%
mutate(age_group=if_else((age %in% c('7','8')),"young","old"))
n.obs = 32
#Breakdown of participants#
#print(length(unique(socialgroups$sub_id))) #72 participants
#table(socialgroups$age)/32
obs.per.group = affiliation_data %>%
group_by(sub_id, age) %>%
summarize(count = n())
kids.per.group = colSums(table(obs.per.group$sub_id, as.factor(obs.per.group$age)))
# 7 yr olds: 33, 8 yr olds: 4, 11 yr olds: 29, 12 year olds: 5
#table(socialgroups$gender)/32 #35 females, 36 males
#table(socialgroups$gender, socialgroups$age)/32 #35 females, 36 males, Females: fifteen 7yos, four 8yos, twelve 11yos, four 12yos, Males: eighteen 7yo, zero 8yo, seventeen 11yo, one 12yo
t.test(score~gender, socialgroups)
#t = 3.5646, df = 2268.5, p-value = 0.0003719, Females(3.10, SD=2.01) Males (2.78, SD = 2.27)
# Are there condition/version effects?
version.lmer.basic = lmer(score ~ age * gender * group  + (1|sub_id), data=socialgroups)
version.lmer = lmer(score ~ age * gender * group + (1|sub_id)+ (1|version), data=socialgroups)
anova(version.lmer.basic, version.lmer)
t.test(score~version, socialgroups) #there is already a correlation between gender and score so the sig difference we get here might be due to that and not version
#the random effects in the model takes into account the difference related to difference in versions
subj.means = socialgroups %>%
group_by(sub_id) %>%
summarize(mean_sub_score=mean(score))
ggplot(subj.means,aes(x=mean_sub_score))+geom_histogram(bins = 15)
shapiro.test(subj.means$mean_sub_score)
###### Affiliation Data ONLY (excludes ladder data) #######
#FYI: Cheat sports and cheat music were reverse coded such that 4=1, 3=2, 2=3, 1=4 in the excel file
#socialgroups %>% filter(group %in% 'american' & type %in% c('friend', 'play', 'cheatsports', 'cheatmusic')) %>%mutate()
# remap_type=function(x){
#   if(x %in% c('friend','play')){
#     return('friendplay')
#   }else if(x %in% c('cheatsports','cheatmusic')){
#     return('cheat')
#   }
# }
#
# socialgroups$type_new = remap_type(socialgroups$type)
affiliation_data = affiliation_data %>%
mutate(threeTypes =
fct_recode(type,
affiliate = 'friend',
affiliate = 'play',
trust = 'secret',
trust = 'help',
loyalty = 'cheatsports',
loyalty = 'cheatmusic')
) %>% droplevels()
#Are the Three item types grouped well? Test for correlations to check our assumptions#
#First calculate a mean score across types (friend, play, cheatmusic...) for each participant then run correlation tests on those means
group.type.lmer = lmer(score ~ group * threeTypes + (1|sub_id), data=affiliation_data)
summary(group.type.lmer)
#children rate americans higher than arabs but not iranians and iranian other
#affiliation: americans higher than arabs only marginally more than other iranians .057
#trust: children trust americans more than arabs and other iranians (.018)
#change base (intercept) so we can see about loyalty
affiliation_data$threeTypes <- relevel(affiliation_data$threeTypes, ref="affiliate")
group.type.lmer = lmer(score ~ group * threeTypes + (1|sub_id), data=affiliation_data)
summary(group.type.lmer)
#barely more likely to be loyal to americans than iranian other (p=.057)
#### Graph mean scores by group ####
affiliation_summary <- affiliation_data %>%
#dplyr::filter(threeTypes == 'affiliate') %>%
#filter(!type %in% c('cheatmusic','cheatsports')) %>%
dplyr::group_by(type, threeTypes) %>%
dplyr::summarize(avg = mean(score), med=median(score),
sd = sd(score), ci.low=ci.low(score), ci.high=ci.high(score))
#this reorganizes the bars for the plot
library(magrittr)
affiliation_summary %<>%
mutate(type = factor(type, levels = c("cheatmusic", "cheatsports",
"friend", "play",
"help", "secret")))
#ratings of all items organized by 3 types (affiliation, loyalty, trust across all groups)
p1 <- ggplot(data = affiliation_summary,
aes(x=type, y=avg , fill=threeTypes)) +
geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=avg-ci.low, ymax=avg+ci.high),
width=.2,
position=position_dodge(.9)) +
#  geom_crossbar(aes(y=med, ymin=med, ymax=med)) +
coord_cartesian(ylim=c(1,4)) +
#scale_fill_manual(values=c("springgreen3",""))+
xlab("Items") +
ylab("Children's Ratings") +
ggtitle("Ratings of Items") +
theme_bw() +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
quartz()
p1
#quartz lets you view the preview of the graph as a pdf
p1.box <- ggplot(data = affiliation_data, aes(x=group, y=score)) +
geom_boxplot()
#### Graph mean scores by group ####
affiliation_summary <- affiliation_data %>%
#dplyr::filter(threeTypes == 'affiliate') %>%
#filter(!type %in% c('cheatmusic','cheatsports')) %>%
dplyr::group_by(type, threeTypes) %>%
dplyr::summarize(avg = mean(score), med=median(score),
sd = sd(score), ci.low=ci.low(score), ci.high=ci.high(score))
p4 <- ggplot(data = affiliation_summary,
aes(x=type, y=avg , fill=type)) +
geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=avg-ci.low, ymax=avg+ci.high),
width=.2,
position=position_dodge(.9)) +
#  geom_crossbar(aes(y=med, ymin=med, ymax=med)) +
#coord_cartesian(ylim=c(0,4)) +
#scale_fill_manual(values=c("springgreen3","deeppink4"))+
xlab("Group") +
ylab("Score: How much do you want to associate with this group?") +
ggtitle("Ratings of Groups") +
theme_bw() +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
p4
#Grey scaled
theme_update(plot.title = element_text(hjust = 0.5), panel.background = element_blank())
pg <- ggplot(data = affiliation_summary,
aes(x=type, y=avg, fill=group)) +
geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=avg-ci.low, ymax=avg+ci.high),
width=.2,
position=position_dodge(.9)) +
#  geom_crossbar(aes(y=med, ymin=med, ymax=med)) +
coord_cartesian(ylim=c(1,4)) +
scale_fill_manual(values=c("black","grey67", "grey40", "grey19"))+
xlab("Group") +
ylab("How much do you want to associate with this group?") +
ggtitle("Ratings of Groups") + theme(plot.title = element_text(hjust = 0.5)) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
pg
# change baseline of group factor
affiliation_data$group <- relevel(affiliation_data$group, ref="iranian")
aov(score ~ group * age_group * gender + Error(sub_id/group), data=affiliation_data))
aov(score ~ group * age_group * gender + Error(sub_id/group), data=affiliation_data)
aov(score ~ group * age_group * gender + Error(sub_id/group), data=affiliation_data) %>% summary()
with(affiliation_data, table(sub_id,group))
View(affiliation_data)
with(affiliation_data, table(sub_id,group, gender))
with(affiliation_data, table(gender,group))
with(affiliation_data, table(gender))
p1.full <- lmer(score ~ group * age_group * gender + (1|sub_id), data=affiliation_data)
lmertest(p1.full)
lmerTest::anova(p1.full)
?lmerTest::anova
??lmerTest::anova
lmerTest::anova(p1.full, ddf = 'lme4')
str(p1.fill)
str(p1.full)
p1.full <- lme4::lmer(score ~ group * age_group * gender + (1|sub_id), data=affiliation_data)
lmerTest::anova(p1.full)
p1.full <- lmerTest::lmer(score ~ group * age_group * gender + (1|sub_id), data=affiliation_data)
lmerTest::anova(p1.full)
version()
R()
R
version
rm(list=ls())
library(ggplot2)
library(lme4)
library(lmerTest)
library(tidyverse)
library(forcats)
library(bootstrap)
library(plyr)
library(dplyr)
#DON'T USE plyr and ddplyr together (it messes up the summarize function)
## Theta and ci functions from Canada MC NEW.R
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),
1000,theta,x,na.rm=na.rm)$thetastar,
.025,na.rm=na.rm)
}
ci.high <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),
1000,theta,x,na.rm=na.rm)$thetastar,
.975,na.rm=na.rm) - mean(x,na.rm=na.rm)
}
setwd("~/Downloads/")
socialgroups<-read.csv('Social Groups Data RC.csv')
socialgroups <- subset(socialgroups, score != "NA")
socialgroups <- tbl_df(socialgroups)
socialgroups$age <- as.factor(socialgroups$age)
socialgroups$score <- as.numeric(socialgroups$score)
socialgroups$version <- as.factor(socialgroups$version)
# create data subsets
young <- socialgroups %>% filter(age %in% c('7','8'))
old <- socialgroups %>% filter(age %in% c('11','12'))
ladder_data <- socialgroups %>% filter(type %in% c("ladder1", "ladder2"))
affiliation_data <- setdiff(socialgroups,ladder_data)
affiliation_data <- affiliation_data %>%
mutate(age_group=if_else((age %in% c('7','8')),"young","old"))
n.obs = 32
#Breakdown of participants#
#print(length(unique(socialgroups$sub_id))) #72 participants
#table(socialgroups$age)/32
obs.per.group = affiliation_data %>%
group_by(sub_id, age) %>%
summarize(count = n())
kids.per.group = colSums(table(obs.per.group$sub_id, as.factor(obs.per.group$age)))
n.obs = 32
#Breakdown of participants#
#print(length(unique(socialgroups$sub_id))) #72 participants
#table(socialgroups$age)/32
obs.per.group = affiliation_data %>%
group_by(sub_id, age) %>%
summarize(count = n())
rm(list=ls())
library(ggplot2)
library(lme4)
library(lmerTest)
library(tidyverse)
library(forcats)
library(bootstrap)
#library(plyr)
library(dplyr)
#DON'T USE plyr and ddplyr together (it messes up the summarize function)
## Theta and ci functions from Canada MC NEW.R
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),
1000,theta,x,na.rm=na.rm)$thetastar,
.025,na.rm=na.rm)
}
ci.high <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),
1000,theta,x,na.rm=na.rm)$thetastar,
.975,na.rm=na.rm) - mean(x,na.rm=na.rm)
}
setwd("~/Downloads/")
socialgroups<-read.csv('Social Groups Data RC.csv')
socialgroups <- subset(socialgroups, score != "NA")
socialgroups <- tbl_df(socialgroups)
socialgroups$age <- as.factor(socialgroups$age)
socialgroups$score <- as.numeric(socialgroups$score)
socialgroups$version <- as.factor(socialgroups$version)
# create data subsets
young <- socialgroups %>% filter(age %in% c('7','8'))
old <- socialgroups %>% filter(age %in% c('11','12'))
ladder_data <- socialgroups %>% filter(type %in% c("ladder1", "ladder2"))
affiliation_data <- setdiff(socialgroups,ladder_data)
affiliation_data <- affiliation_data %>%
mutate(age_group=if_else((age %in% c('7','8')),"young","old"))
n.obs = 32
#Breakdown of participants#
#print(length(unique(socialgroups$sub_id))) #72 participants
#table(socialgroups$age)/32
obs.per.group = affiliation_data %>%
group_by(sub_id, age) %>%
summarize(count = n())
kids.per.group = colSums(table(obs.per.group$sub_id, as.factor(obs.per.group$age)))
t.test(score~gender, socialgroups)
# Are there condition/version effects?
version.lmer.basic = lmer(score ~ age * gender * group  + (1|sub_id), data=socialgroups)
# change baseline of group factor
affiliation_data$group <- relevel(affiliation_data$group, ref="iranian")
p1.full <- lme4::lmer(score ~ group * age_group * gender + (1|sub_id), data=affiliation_data)
summary(p1.full)
lmerTest::anova(p1.full)
p1.full <- lmerTest::lmer(score ~ group * age_group * gender + (1|sub_id), data=affiliation_data)
lmerTest::anova(p1.full)
df <- data.frame(Part = c("Servers", "Servers", "Cups", "CPU", "CPU"),
WONumber = c("Pre-0918", "Pre-1018", "Pre-1018", "Pre-1018", "Pre-1118"),
WODate = c("2018-09-01", "2018-10-01", "2018-10-01", "2018-10-01", "2018-11-01"),
WOQty = 10:14,
Shipped = c(10, 10, 15, 30, 30))
df
df
ideal <- data.frame(Part = c("Servers", "Cups", "CPU"),
WONumber = c("Pre-0918", "Pre-1018", "Pre-1018"),
WODate = c("2018-09-01", "2018-10-01", "2018-10-01"),
WOQty = c(10, 12, 13),
Shipped = c(10, 15, 30))
ideal
df <- data.frame(Part = c("Servers", "Servers", "Cups", "CPU", "CPU"),
WONumber = c("Pre-0918", "Pre-1018", "Pre-1018", "Pre-1018", "Pre-1118"),
WODate = c("2018-09-01", "2018-10-01", "2018-10-01", "2018-10-01", "2018-11-01"),
WOQty = 10:14,
Shipped = c(10, 10, 15, 30, 30)) %>%
df %>% glimpse
df <- data.frame(Part = c("Servers", "Servers", "Cups", "CPU", "CPU"),
WONumber = c("Pre-0918", "Pre-1018", "Pre-1018", "Pre-1018", "Pre-1118"),
WODate = c("2018-09-01", "2018-10-01", "2018-10-01", "2018-10-01", "2018-11-01"),
WOQty = 10:14,
Shipped = c(10, 10, 15, 30, 30)) %>%
df %>% glimpse()
df <- data.frame(Part = c("Servers", "Servers", "Cups", "CPU", "CPU"),
WONumber = c("Pre-0918", "Pre-1018", "Pre-1018", "Pre-1018", "Pre-1118"),
WODate = c("2018-09-01", "2018-10-01", "2018-10-01", "2018-10-01", "2018-11-01"),
WOQty = 10:14,
Shipped = c(10, 10, 15, 30, 30)) %>%
glimpse(df)
df <- data.frame(Part = c("Servers", "Servers", "Cups", "CPU", "CPU"),
WONumber = c("Pre-0918", "Pre-1018", "Pre-1018", "Pre-1018", "Pre-1118"),
WODate = c("2018-09-01", "2018-10-01", "2018-10-01", "2018-10-01", "2018-11-01"),
WOQty = 10:14,
Shipped = c(10, 10, 15, 30, 30))
glimpse(df)
df <- data.frame(Part = c("Servers", "Servers", "Cups", "CPU", "CPU"),
WONumber = c("Pre-0918", "Pre-1018", "Pre-1018", "Pre-1018", "Pre-1118"),
WODate = c("2018-09-01", "2018-10-01", "2018-10-01", "2018-10-01", "2018-11-01"),
WOQty = 10:14,
Shipped = c(10, 10, 15, 30, 30)) %>%
mutate(WODate = lubridate::ymd(WODate))
df <- data.frame(Part = c("Servers", "Servers", "Cups", "CPU", "CPU"),
WONumber = c("Pre-0918", "Pre-1018", "Pre-1018", "Pre-1018", "Pre-1118"),
WODate = c("2018-09-01", "2018-10-01", "2018-10-01", "2018-10-01", "2018-11-01"),
WOQty = 10:14,
Shipped = c(10, 10, 15, 30, 30)) %>%
mutate(WODate = lubridate::ymd(WODate))
df
df <- data.frame(Part = c("Servers", "Servers", "Cups", "CPU", "CPU"),
WONumber = c("Pre-0918", "Pre-1018", "Pre-1018", "Pre-1018", "Pre-1118"),
WODate = c("2018-09-01", "2018-10-01", "2018-10-01", "2018-10-01", "2018-11-01"),
WOQty = 10:14,
Shipped = c(10, 10, 15, 30, 30)) %>%
mutate(WODate = lubridate::ymd(WODate)) %>%
group_by(Part) %>%
filtr(WODate = min(WODate))
df <- data.frame(Part = c("Servers", "Servers", "Cups", "CPU", "CPU"),
WONumber = c("Pre-0918", "Pre-1018", "Pre-1018", "Pre-1018", "Pre-1118"),
WODate = c("2018-09-01", "2018-10-01", "2018-10-01", "2018-10-01", "2018-11-01"),
WOQty = 10:14,
Shipped = c(10, 10, 15, 30, 30))
df %>%
mutate(WODate = lubridate::ymd(WODate)) %>%
group_by(Part) %>%
filetr(WODate = min(WODate))
df %>%
mutate(WODate = lubridate::ymd(WODate)) %>%
group_by(Part) %>%
filter(WODate = min(WODate))
df %>%
mutate(WODate = lubridate::ymd(WODate)) %>%
group_by(Part) %>%
filter(WODate == min(WODate))
ideal
# mathematical symbols
d+ =2
# Vectors are a fundamental object in R:
37
# Now, moving on the vectors, we can store more items into one variable
# here we use a function called c()
# whatever you put between () must be separated by a comma
e = c(1, 2, 3, 4)
e
f = c(1, "two", 3, 'four')
f
g <- matrix(1:9, nrow = 3)
g
x1 = c(65, 80, 71, 50, 75, 90)
x2 = c(71, 87, 71, 60, 64, 94)
d = x2 - x1
d2 = d ^ 2
d
d2
sum(d)
sum(d2)
mean(d)
SS = sum(d2) - sum(d)^2 / length(d)
s2 = SS / (length(d) - 1)
s = sqrt(s2)
smd = s / sqrt(length(d))
t = mean(d) / smd
t
#
# # Here it is with the built-in t.test function
t.test(x2, x1, paired = TRUE)
?glimpse
# generally, we'll create new columns using the mutate() function from dplyr:
cars3 = mtcars %>%
mutate(Score = as.character(gear))
cars3
summary(mtcars$gear)
mtcars[1]
# here we see that it is a data frame with 11 variables
# unlike matricies that use [], data frames use $ (altough [] can work)
mtcars$mpg # pulls out a vector list for the mpg column
# here we see that it is a data frame with 11 variables
# unlike matricies that use [], data frames use $ (altough [] can work)
mtcars$mpg # pulls out a vector list for the mpg column
path = '/Users/Jarrett/Documents/UCSD/Research/Retrieval Practice/Optimal TE/OPT-TE_0/data/'
fn = 'Opt0-S1.csv'
fp = paste0(path,fn)
testFile = read.csv(fp)
head(testFile)
str(testFile)
# For Windows: setwd("C:/Users/...")
setwd('~/Documents/UCSD/Research/Process-Shift/data/')
testFile = read_csv('proc_shif_data.csv')
head(testFile)
str(testFile)
glimpse(testFile)
head(testFile)
rm(list=ls())

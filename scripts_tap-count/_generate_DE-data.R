library(dplyr)
library(ggplot2)


#### Parameters ####

# data level
nsubs <- 20
nitems <- 10
ntrials <- 100


# model parameter means (taken from Evans et al. 2018 fig 1)
# Figure 1. Fits to two simulated data sets (black circles), generated by the 
# exponential function (left panel; parameters: alpha = 1, beta = 2, r = 0.2, t0** = 0.3, and sigma = 0.1) 
# and the power function (right panel; parameters: alpha = 1, beta = 2, r = 0.7, t0 = 0.3, and sigma = 0.1).
# **t0 <- .3 # i.e. fastest possible response-contigent RT, in seconds. Ignore this for now. 

#### EQUATION:  RT = A + B*exp(-r*N) + error ~ N(0,sigma) \
A <- 1 ; A_sigma <- .01 # overall mean; sd of A (alpha) components
B <- 2; B_sigma <- .2 # beta
r <- .2; r_sigma <- .02 # rate
sigma <- .1 # overall sigma (sd(y~ y_hat))


# generate the full subject*item effect matrix for a single parameter
gen_param <- function(param_name, param_mu, # just for reporting back, not used computationally
                      nsubs, nitems, 
                      sigma, # sigma for overall variance from the mean power curve
                      showWork=F, # do we want to output the matrices leading to the final parameters?
                      sd = param_mu*.1, # sd of random effects; sub*item's sd is /2 (good idea?)
                      mu_bias=0) # should ranefs be biased in either direction (weird)?
  {
  sub_offsets <- rnorm(nsubs,mu_bias,sd)
  item_offsets <- rnorm(nitems,mu_bias,sd)
  out <- list(param_mu, # parameter mean
              sub_offsets,
              matrix(rep(sub_offsets, times = nitems),nrow = nsubs), # subject offsets as sub*item matrix
              item_offsets,
              matrix(rep(item_offsets, each = nsubs),nrow = nsubs), # item offsets as sub*item matrix
              matrix(rnorm(nsubs*nitems,mu_bias,sd/2),nrow = nsubs) # subj*item offsets

  )
  names(out) <- c(param_name, #1
                  paste0(param_name,'_sub'), #2
                  paste0(param_name,'_sub_mat'), #3
                  paste0(param_name,'_item'), #4
                  paste0(param_name,'_item_mat'),#5
                  paste0(param_name,'_subItem'))#6
  out[[paste0(param_name,'_PAREMETER')]] <- out[[1]] + out[[3]] + out[[5]] + out[[6]] #7
  if(showWork){
    out
  } else{
    out[[7]]
  }
}

# take a matrix of predicted RTs by subject and item for a given trial, convert it to a df
RTmat2DF <- function(mat, trial){
  subs <- 1:nrow(mat)
  items <- 1:ncol(mat)
  as_tibble(expand.grid(item = items, sub = subs)) %>%
    mutate(trial = trial)%>%
    rowwise() %>%
    mutate(RT_hat = mat[sub,item]) %>%
    select(sub, item, trial, RT_hat)
}

# actually generate the data
DE-generate-RTs <- function(nsubs, nitems, ntrials,
                            alpha, beta, rate, sigma, # overall sigma
                            a_sig=alpha*.1, b_sig=beta*.1, r_sig=rate*.1){
  params <- list(
    alpha = gen_param('alpha',alpha, nsubs, nitems, sigma, sd = a_sig, showWork=F), # changing showWork changes structure of output (bad)
    beta = gen_param('beta', beta, nsubs, nitems, sigma, sd = b_sig, showWork=F),
    rate = gen_param('rate', rate, nsubs, nitems, sigma, sd = r_sig, showWork=F))
  
  trials <- 1:ntrials
  # create a list, indexed by trial, of subject * item matrices of predicted RTs (pre-noise)
  RT_hat_by_trial <- lapply(trials, function(N) params$alpha + params$beta * exp(-params$rate * N))
  # convert all those matrices to data frames and staple them together 
  pred_dat <-  bind_rows(lapply(1:length(RT_hat_by_trial), function(i) RTmat2DF(RT_hat_by_trial[[i]], i))) %>%
    # add some noise (based on sigma, set globally above)
    mutate(error = rnorm(n(),0,sigma),
           RT = RT_hat + error)
}

#### EQUATION:  RT = A + B*exp(-r*N) + error~ N(0,sigma) #### 

# params <- gen_data(nsubs, nitems, ntrials,
#                    A, B, r, sigma,
#                    A_sigma, B_sigma, r_sigma)





library(dplyr)
library(ggplot2)


#### Parameters ####

# data level
nsubs <- 10
nitems <- 5
ntrials <- 50


# model parameter means (taken from Evans et al. 2018 fig 1)
# Figure 1. Fits to two simulated data sets (black circles), generated by the 
# exponential function (left panel; parameters: alpha = 1, beta = 2, r = 0.2, t0** = 0.3, and sigma = 0.1) 
# and the power function (right panel; parameters: alpha = 1, beta = 2, r = 0.7, t0** = 0.3, and sigma = 0.1).
# **t0 <- .3 # i.e. fastest possible response-contigent RT, in seconds. Ignore this for now. 


sigma <- .1 # overall sigma (sd(y~ y_hat))
#### DE EQUATION:  RT = A + B*exp(-r*N) + error ~ N(0,sigma) 
## See Heathcote p. 15 for priors
A_de <- 1 ; A_de_sigma <- .05 # overall mean; sd of A (alpha) components A_ ~ N(A, A_sigma)
B_de <- 2; B_de_sigma <- .3 # beta |  B_ ~ N(B, B_sigma)
r_de <- .2; r_de_sigma <- .025 # rate | r ~ N(r, r_sigma)
tau_de <- 0; # currently ignored

#### PS EQUATION:  RT = A + B*N^(-r) + error ~ N(0,sigma) 
## See Heathcote p. 15 for priors
pRet_A = .25; pRet_A_sigma = .05
pRet_B = ntrials/4; pRet_B_sigma = 3 # dunno, weird initializations, sorry.
mu_ps = 2 ; mu_ps_sigma = .3 # setting the same as beta, which i think makes sense. 
A_ps <- 1 ; A_ps_sigma <- .05 # overall mean; sd of A (alpha) components A_ ~ N(A, A_sigma)
B_ps <- 2; B_ps_sigma <- .3 # beta |  B_ ~ N(B, B_sigma)
r_ps <- .7; r_ps_sigma <- .025 # rate | r ~ N(r, r_sigma)
tau_ps <- 0; # currently ignored


# generate the full subject*item effect matrix for a single parameter
gen_param <- function(param_name, param_mu, # just for reporting back, not used computationally
                      nsubs, nitems,
                      showWork=F, # do we want to output the matrices leading to the final parameters?
                      sd = param_mu*.1, # sd of random effects; sub*item's sd is /2 (good idea?)
                      mu_bias=0) # should ranefs be biased in either direction (weird)?
  {
  sub_offsets <- rnorm(nsubs,mu_bias,sd)
  item_offsets <- rnorm(nitems,mu_bias,sd)
  out <- list(param_mu, # parameter mean
              sub_offsets,
              matrix(rep(sub_offsets, times = nitems),nrow = nsubs), # subject offsets as sub*item matrix
              item_offsets,
              matrix(rep(item_offsets, each = nsubs),nrow = nsubs), # item offsets as sub*item matrix
              matrix(rnorm(nsubs*nitems,mu_bias,sd/2),nrow = nsubs) # subj*item offsets

  )
  names(out) <- c(param_name, #1
                  paste0(param_name,'_sub'), #2
                  paste0(param_name,'_sub_mat'), #3
                  paste0(param_name,'_item'), #4
                  paste0(param_name,'_item_mat'),#5
                  paste0(param_name,'_subItem'))#6
  out[[paste0(param_name,'_PAREMETER')]] <- out[[1]] + out[[3]] + out[[5]] + out[[6]] #7
  if(showWork){
    out
  } else{
    out[[7]]
  }
}

# take a matrix of predicted RTs by subject and item for a given trial, convert it to a df
RTmat2DF <- function(RT_mat, choice_mat, trial){
  subs <- 1:nrow(RT_mat)
  items <- 1:ncol(RT_mat)
  as_tibble(expand.grid(item = items, sub = subs)) %>%
    mutate(trial = trial)%>%
    rowwise() %>%
    mutate(isRetrieval = as.logical(choice_mat[sub,item]),
           RT_hat = RT_mat[sub,item]) %>%
    select(sub, item, trial, isRetrieval, RT_hat)
}

# actually generate the data (DE)
DE_generate_RTs <- function(nsubs, nitems, ntrials,
                            alpha, beta, rate, sigma, # overall sigma
                            a_sig=alpha*.1, b_sig=beta*.1, r_sig=rate*.1,
                            trunc_min = 10e-6){ # min values for should-be positive values
  params <- list(
    alpha = gen_param('alpha',alpha, nsubs, nitems, sd = a_sig, showWork=F), # changing showWork changes structure of output (bad)
    beta = gen_param('beta', beta, nsubs, nitems, sd = b_sig, showWork=F),
    rate = gen_param('rate', rate, nsubs, nitems, sd = r_sig, showWork=F))
  
  trials <- 1:ntrials
  # create a list, indexed by trial, of subject * item matrices of predicted RTs (pre-noise)
  RT_hat_by_trial <- lapply(trials, function(N){
    #### EQUATION:  RT = A + B*exp(-r*N) + error~ N(0,sigma) #### 
    params$alpha + params$beta * exp(-params$rate* N)})
  # convert all those matrices to data frames and staple them together
  RT_hat_by_trial
  pred_dat <-  bind_rows(lapply(1:length(RT_hat_by_trial), function(i) RTmat2DF(RT_hat_by_trial[[i]], i))) %>%
    # add some noise (based on sigma, set globally above)
    mutate(error = rnorm(n(),0,sigma),
           RT = RT_hat + error)
}


# actually generate the data
generate_RTs <- function(f, #'de' or 'ps'
                            nsubs, nitems, ntrials,
                            alpha, beta, rate, sigma, # overall sigma
                            a_sig=alpha*.1, b_sig=beta*.1, r_sig=rate*.1,
                            mu = beta, mu_sig = b_sig, # ps_algorithm arguments
                            pRet_A = .25, pRet_B = ntrials/4,# tricky to set default to .25 of the way...
                            pRet_A_sig =.05, pRet_B_sig = 3, # again, weird defaults...
                            trunc_min = 10e-6){ # min values for should-be positive values
  params <- list(
    alpha = gen_param('alpha',alpha, nsubs, nitems, sd = a_sig, showWork=F), # changing showWork changes structure of output (bad)
    beta = gen_param('beta', beta, nsubs, nitems, sd = b_sig, showWork=F),
    rate = gen_param('rate', rate, nsubs, nitems, sd = r_sig, showWork=F))
  if(f == 'ps'){
    params$mu <- gen_param('mu', mu, nsubs, nitems, sd = mu_sig, showWork=F)
    params$pRet_A <- gen_param('pRet_A', pRet_A, nsubs, nitems, sd = pRet_A_sig, showWork=F)
    params$pRet_B <- gen_param('pRetB', pRet_B, nsubs, nitems, sd = pRet_B_sig, showWork=F)
  }
  
  trials <- 1:ntrials
  # create a list, indexed by trial, of subject * item matrices of predicted RTs (pre-noise)
  if (f == 'de'){
    RT_hat_by_trial <- lapply(trials, function(N){
      #### EQUATION:  RT = A + B*exp(-r*N) + error~ N(0,sigma) #### 
      params$alpha + params$beta * exp(-params$rate* N)})
    
  } else if (f == 'ps'){
    # get p(retrieval on each trial)
    pRet_by_trial <- lapply(trials, function(N){
      # logistic function modeling p(retrieval)
      1/(1 + exp(-params$pRet_A*(N-params$pRet_B)))})
    # sample whether or not actually retrieval
    isRet_by_trial <- lapply(pRet_by_trial, function(m){
      apply(m, c(1,2), function(p) rbinom(1,1,p))})
    RT_hat_RET_by_trial <- lapply(trials, function(N){
      # In here figure out how to deal with RT_ret ~ ntrials(OF THAT STRATEGY)
      #### EQUATION:  RT = A + B*N^(-r) + error~ N(0,sigma) #### 
      params$alpha + params$beta * N^(-params$rate)}) 
    RT_hat_ALG_by_trial <- lapply(trials, function(N){
      params$mu})
    RT_hat_by_trial <- lapply(trials, function(N){
      # compute the weighted sum of the two strategies' RTs (0,1 weights)
      isRet_by_trial[[N]]*RT_hat_RET_by_trial[[N]] +
        (1-isRet_by_trial[[N]])*RT_hat_ALG_by_trial[[N]]
    })
  } else {
    RT_hat_by_trial <- NULL # throw a better error here
  }
  # convert all those matrices to data frames and staple them together
  pred_dat <-  bind_rows(lapply(1:length(RT_hat_by_trial), function(i) {
    RTmat2DF(RT_hat_by_trial[[i]], isRet_by_trial[[i]], i)})) %>%
    # add some noise (based on sigma, set globally above)
    mutate(error = rnorm(n(),0,sigma),
           RT = RT_hat + error,
           fn = f)
}


RTs <-generate_RTs(f = 'ps',
                nsubs, nitems, ntrials,
                A_de, B_de, r_de, sigma,
                A_de_sigma, B_de_sigma, r_de_sigma)
RTs %>% 
  ggplot(aes(x = trial, y = RT, color = isRetrieval)) + geom_point() + facet_grid(sub~item) + theme_minimal()

# get strategy choice per trial included in data frame conversion
